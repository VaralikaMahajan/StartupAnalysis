# Data 

## Sources

<b>Dataset description - </b>

The startup dataset is a combination of two datasets: the Unicorn startup dataset and the failed startup dataset. 
The Unicorn dataset provides information about the valuation, the founding year, country, city, industry, the investors, the total amount raised, the financial stage, investors count, the deal terms, and portfolio exits. It has a total of 13 columns. The datatypes involved in this dataset are categorical and numerical, having a few missing values.

The failed startup dataset provides information regarding the status, the amount raised in different funding rounds, categories, and headquarters city. It has a total of 6 columns. The datatypes involved in this dataset are categorical and numerical, having a few missing values.

Datasets usually have three general properties:

<b>Dimensionality:</b> 
The number of attributes the objects in a dataset have. The two start-up datasets have many features and thus can be considered high-dimensional datasets.

<b>Sparsity:</b>
It happens when a significant portion of the variable's cells do not contain any actual data. This type can be an empty or Null value and includes missing values. In the two datasets, some columns have sparse data.

<b>Resolution:</b>
The level of resolution affects the patterns in the data. A pattern may not be seen or taken as noise data if the resolution is too fine; if the resolution is too coarse, the pattern may disappear. The two datasets are relatively coarse and sparse; thus, the patterns are easily identifiable.

```{r, warning = FALSE, results = 'hide', message = FALSE}
uni <- read.csv("Unicorn_Companies.csv")
ab <- read.csv("AB.csv")
```

## Cleaning / transformation

We conducted an exploratory data analysis to find out anomalies.
<br>
<b>Observations:</b>
HeadquartersCity is a column with more than 40% missing values.
Deal terms and Portfolio exits are irrelevant and do not impact our analysis.

When you have clean data, you can make decisions using the highest-quality information and eventually boost productivity. Most data cleaning procedures adhere to a common framework: choose the important data points that are necessary for your study. Gather the information you want, then sort and arrange it. Find and eliminate any values that are redundant or unnecessary.

Similar steps were taken by us: 
We determined which columns weren't important for our study and then got to work removing them. Then, we looked for NULL or 0 values in the data. When we saw that the City Column had several missing values, we decided to replace null with the word "Others" because it was a pertinent column and couldn't be replaced with anything else.
Additionally, we made sure that all of the numerical columns were changed to numeric for analysis simplicity.


<b>Strategies used for missing value imputation:</b>
We have cleaned the dataset in such a way that we find a close and appropriate result. 
HeadquartersCity with Null values has been filled with “Others” to treat them as a separate category.
We have removed data columns that were not relavent to our analysis, such as Deal terms and Portfolio exits.


```{r, warning = FALSE, results = 'hide', message = FALSE}
uni <- subset(uni, select = c("Deal.Terms","Portfolio.Exits"))

ab$HeadquartersCity <- sub("^$", "Other", ab$HeadquartersCity)
```

## Missing value analysis

After analyzing each column in both datasets, we carefully understand the reasons behind the missing values as it is crucial to find out the strategy for handling them.

There are two primary ways of handling missing values:
<br>
<b>a. Deleting the missing rows</b>
This approach is used when the missing value is of the type Missing Not At Random(MNAR). It can be deleted if it belongs to this category. 
The datasets chosen do not have missing values at random and thus, we do not delete the individual rows. Also, since every row does not have many missing values, we do not delete the rows.
<br>
<b>b. Imputing the missing values</b>
If there is a possibility of making an educated guess, as to which category the missing values belong to, this value can be included in the columns having missing values. Thus, we choose this technique to include ‘Others’ as a value in the Headquarters city column of AB dataset which categorizes all other cities as other.

The failed startup dataset has one column having more than 40% rows to be missing. These missing values pertain to the Headquarters city column. The dataset has been imputed with the string value ‘Others’ and treated as a separate category.


```{r, warning = FALSE, results = 'hide', message = FALSE}

x_ab <- data.frame(Categories = c('Amount raised', 'Headquarters city'), Count = c(372, 208))
x_uni <- data.frame(Categories = c('Portfolio Exits', 'Financial Stage'), Count = c(988, 988))


ggplot(x_ab) +
  aes(x = Categories, y = Count) +
  geom_col(fill = "#112446") +
  labs(title = "Missing Value Analysis(0 or N/A)") +
  theme_minimal()
  
ggplot(x_uni) +
  aes(x = Categories, y = Count) +
  geom_col(fill = "#112446") +
  labs(title = "Missing value analysis(0 or none)") +
  theme_minimal()
```
